{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-Anime-model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fukushun1994/RNN-Anime-model/blob/master/RNN_Anime_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "aNbXs-n-fYqC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 環境構築\n"
      ]
    },
    {
      "metadata": {
        "id": "kZotviBtgg_H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GPUの設定\n",
        "\n",
        "ランタイム > ランタイムのタイプを変更 で ハードウェアアクセラレータをGPUに設定\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_MdB2tFkozhL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# データの準備\n"
      ]
    },
    {
      "metadata": {
        "id": "zQPYWRcpo2Da",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Google Drive のマウント"
      ]
    },
    {
      "metadata": {
        "id": "VjSVqUcXpsGK",
        "colab_type": "code",
        "outputId": "78a2cd08-4a54-48b2-e1a5-74eab7992fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "udVUnXpdtAoS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## データの取得"
      ]
    },
    {
      "metadata": {
        "id": "oudjKZQau5v7",
        "colab_type": "code",
        "outputId": "a41a5b3f-930a-43b7-8113-9a74792cfae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "DATA_DIR = '/content/gdrive/My Drive/YuyushikiData/'\n",
        "ZIP_FILE_NAMES = ['ep1.zip']\n",
        "SKIP = 1\n",
        "threshold = 100\n",
        "\n",
        "total_length = 0\n",
        "data_list = []\n",
        "for zip_file_name in ZIP_FILE_NAMES:\n",
        "  data = []\n",
        "  with zipfile.ZipFile(DATA_DIR+zip_file_name, 'r') as zp:\n",
        "    images = sorted(zp.namelist())\n",
        "    image_count = len(images)\n",
        "    total_length += image_count\n",
        "    print('open {} ({} images)'.format(zip_file_name, image_count))\n",
        "    for i in range(0, image_count, SKIP):\n",
        "      image_name = images[i]\n",
        "      print('\\r{}/{}'.format(i, image_count), end='')\n",
        "      with zp.open(image_name, 'r') as fp:\n",
        "        with Image.open(fp) as img:\n",
        "          img_vec = np.array(img)[:,:,:3]/255\n",
        "          if len(data) == 0 or np.sum(np.abs(img_vec - data[-1])) > threshold:\n",
        "            data.append(img_vec)\n",
        "  print('\\nadded {} images'.format(len(data)))\n",
        "  data_list.append(data)\n",
        "\n",
        "image_shape = data_list[0][0].shape\n",
        "print('')\n",
        "print(image_shape)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "open ep1.zip (26235 images)\n",
            "26234/26235\n",
            "added 9318 images\n",
            "\n",
            "(72, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "flZ-QNhQgsje",
        "colab_type": "code",
        "outputId": "405f73d3-128c-405e-ccb7-043e7a00878c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        3.3G        6.3G        884K        3.2G         11G\n",
            "Swap:            0B          0B          0B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5EKCyQ7YZLbo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ジェネレータの作成"
      ]
    },
    {
      "metadata": {
        "id": "TULEMKP8cRvA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_generator(data, seq_len, batch_size):\n",
        "  available_indices = []\n",
        "  flatten_data = []\n",
        "  offset = 0\n",
        "  for d in data:\n",
        "    available_indices += list(range(offset, offset+len(d)-seq_len))\n",
        "    flatten_data += d\n",
        "    offset += len(d)\n",
        "  while True:\n",
        "    indices = np.random.choice(available_indices, batch_size, replace=False)\n",
        "    yield (\n",
        "      np.stack([flatten_data[i:i+seq_len] for i in indices]),\n",
        "      np.stack([flatten_data[i+1:i+1+seq_len] for i in indices])\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ow-Oe_K7h830",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "61f88af0-3758-42b1-9ffe-3b76901a6df7"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "cyiUzr9O0jSW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# モデルの構築\n"
      ]
    },
    {
      "metadata": {
        "id": "p6N9L9ul0lHU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# code from https://github.com/keras-team/keras/blob/master/examples/conv_lstm.py\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Reshape, Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "\n",
        "FILTER_NUM = 32\n",
        "KERNEL_SIZE = (3, 3)\n",
        "\n",
        "def create_model(input_shape):\n",
        "  flat_dim = np.prod(input_shape[1:])\n",
        "  seq = Sequential()\n",
        "  seq.add(ConvLSTM2D(filters=FILTER_NUM, kernel_size=KERNEL_SIZE,\n",
        "                     input_shape=input_shape,\n",
        "                     padding='same', return_sequences=True))\n",
        "  seq.add(BatchNormalization())\n",
        "  \n",
        "  seq.add(ConvLSTM2D(filters=FILTER_NUM, kernel_size=KERNEL_SIZE,\n",
        "                     padding='same', return_sequences=True))\n",
        "  seq.add(BatchNormalization())\n",
        "  '''\n",
        "  seq.add(ConvLSTM2D(filters=FILTER_NUM, kernel_size=KERNEL_SIZE,\n",
        "                     padding='same', return_sequences=True))\n",
        "  seq.add(BatchNormalization())\n",
        "\n",
        "  seq.add(ConvLSTM2D(filters=FILTER_NUM, kernel_size=KERNEL_SIZE,\n",
        "                     padding='same', return_sequences=True))\n",
        "  seq.add(BatchNormalization())\n",
        "  seq.add(Conv3D(filters=3, kernel_size=(3, 3, 3),\n",
        "               activation='sigmoid',\n",
        "               padding='same', data_format='channels_last'))\n",
        "  '''\n",
        "  seq.add(ConvLSTM2D(filters=3, kernel_size=KERNEL_SIZE,\n",
        "                     padding='same', return_sequences=True))\n",
        "  seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
        "  return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4UPnseVvTPzs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 学習\n"
      ]
    },
    {
      "metadata": {
        "id": "2C2NJKNyTTOz",
        "colab_type": "code",
        "outputId": "53942a4d-a453-45dc-ef18-f47c21e2f7bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "SEQ_LENGTH = 5\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "seq = create_model((SEQ_LENGTH,) + image_shape)\n",
        "cb = ModelCheckpoint('model.h5', save_best_only=True)\n",
        "steps_per_epoch = 1000\n",
        "seq.fit_generator(\n",
        "    data_generator(data_list, SEQ_LENGTH, BATCH_SIZE),\n",
        "    steps_per_epoch = steps_per_epoch,\n",
        "    epochs=10,\n",
        "    callbacks = [cb])\n",
        "seq.save_weights('/tmp/weights.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 596s 596ms/step - loss: 0.5372\n",
            "Epoch 2/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 590s 590ms/step - loss: 0.5048\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 592s 592ms/step - loss: 0.5027\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 591s 591ms/step - loss: 0.5032\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 591s 591ms/step - loss: 0.5022\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 591s 591ms/step - loss: 0.5008\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 591s 591ms/step - loss: 0.5006\n",
            "Epoch 8/10\n",
            " 608/1000 [=================>............] - ETA: 3:51 - loss: 0.5008"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PQF4_-K9_3JH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 生成"
      ]
    },
    {
      "metadata": {
        "id": "EEpvyWiK-6sY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p preds\n",
        "!rm preds/*\n",
        "\n",
        "PREDICT_LEN = 30\n",
        "\n",
        "predict_model = create_model((1,) + image_shape)\n",
        "predict_model.load_weights('/tmp/weights.h5')\n",
        "\n",
        "seed = np.array(data_list[0][4000:4005])\n",
        "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
        "for i in range(seed.shape[1]):\n",
        "  predict_model.predict(seed[:,i:i+1])\n",
        "  \n",
        "predictions = [seed[:,-1:]]\n",
        "for i in range(PREDICT_LEN):\n",
        "  last_pred = predictions[-1]\n",
        "  pred = predict_model.predict(last_pred)\n",
        "  predictions.append(pred)\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(BATCH_SIZE):\n",
        "    img_array = (predictions[i][j][0] * 255).astype(np.uint8)\n",
        "    img = Image.fromarray(img_array)\n",
        "    img.save('preds/pred_{}_{}.png'.format(j, i), 'PNG')\n",
        "\n",
        "!zip -r preds.zip preds\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('preds.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}